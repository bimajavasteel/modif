from typing import Any, List, Callable
import cv2
import threading

import roop.globals
import roop.processors.frame.core
from roop.core import update_status
from roop.face_analyser import get_many_faces
from roop.typing import Frame, Face
from roop.utilities import conditional_download, resolve_relative_path, is_image, is_video

FACE_ENHANCER = [None, None]  # Dual GPU support
THREAD_SEMAPHORE = threading.Semaphore()
THREAD_LOCK = threading.Lock()
NAME = 'ROOP.FACE-ENHANCER-DUAL-GPU'

def get_face_enhancer(device_id: int = 0) -> Any:
    global FACE_ENHANCER

    with THREAD_LOCK:
        if FACE_ENHANCER[device_id] is None:
            from gfpgan.utils import GFPGANer
            model_path = resolve_relative_path('../models/GFPGANv1.4.pth')
            FACE_ENHANCER[device_id] = GFPGANer(model_path=model_path, upscale=1, device=get_device(device_id))
    return FACE_ENHANCER[device_id]

def get_device(device_id: int = 0) -> str:
    if 'CUDAExecutionProvider' in roop.globals.execution_providers:
        return f'cuda:{device_id}'
    if 'CoreMLExecutionProvider' in roop.globals.execution_providers:
        return 'mps'
    return 'cpu'

def clear_face_enhancer() -> None:
    global FACE_ENHANCER
    FACE_ENHANCER = [None, None]

def pre_check() -> bool:
    download_directory_path = resolve_relative_path('../models')
    conditional_download(download_directory_path, ['https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/GFPGANv1.4.pth'])
    return True

def pre_start() -> bool:
    if not is_image(roop.globals.target_path) and not is_video(roop.globals.target_path):
        update_status('Select an image or video for target path.', NAME)
        return False
    return True

def post_process() -> None:
    clear_face_enhancer()

def enhance_face(target_face: Face, temp_frame: Frame, device_id: int = 0) -> Frame:
    frame_height, frame_width = temp_frame.shape[:2]
    start_x, start_y, end_x, end_y = map(int, target_face['bbox'])
    
    face_w, face_h = end_x - start_x, end_y - start_y
    if face_w <= 0 or face_h <= 0:
        return temp_frame

    pad_ratio = max(0.1, min(0.3, 100 / max(face_w, face_h)))
    padding_x = int(face_w * pad_ratio)
    padding_y = int(face_h * pad_ratio)
    
    start_x = max(0, start_x - padding_x)
    start_y = max(0, start_y - padding_y)
    end_x = min(frame_width, end_x + padding_x)
    end_y = min(frame_height, end_y + padding_y)
    
    temp_face = temp_frame[start_y:end_y, start_x:end_x]
    if temp_face.size == 0:
        return temp_frame

    with THREAD_SEMAPHORE:
        try:
            _, _, enhanced_face = get_face_enhancer(device_id).enhance(
                temp_face,
                paste_back=True
            )
            if enhanced_face.shape == temp_face.shape:
                temp_frame[start_y:end_y, start_x:end_x] = enhanced_face
        except Exception as e:
            print(f"[WARNING] Enhance face failed on GPU {device_id}: {e}")
    
    return temp_frame

def process_frame(source_face: Face, reference_face: Face, temp_frame: Frame) -> Frame:
    many_faces = get_many_faces(temp_frame)
    if many_faces:
        for target_face in many_faces:
            # Distribute enhancement between GPUs based on face position
            device_id = 0 if target_face.bbox[0] < temp_frame.shape[1] // 2 else 1
            temp_frame = enhance_face(target_face, temp_frame, device_id)
    return temp_frame

def process_frames(source_path: str, temp_frame_paths: List[str], update: Callable[[], None]) -> None:
    # Distribute frames between GPUs
    half = len(temp_frame_paths) // 2
    
    for i, temp_frame_path in enumerate(temp_frame_paths):
        temp_frame = cv2.imread(temp_frame_path)
        device_id = 0 if i < half else 1
        result = process_frame(None, None, temp_frame)
        cv2.imwrite(temp_frame_path, result)
        if update:
            update()

def process_image(source_path: str, target_path: str, output_path: str) -> None:
    target_frame = cv2.imread(target_path)
    result = process_frame(None, None, target_frame)
    cv2.imwrite(output_path, result)

def process_video(source_path: str, temp_frame_paths: List[str]) -> None:
    roop.processors.frame.core.process_video(None, temp_frame_paths, process_frames)
